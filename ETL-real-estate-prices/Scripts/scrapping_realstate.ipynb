{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = r\"C:\\Users\\ahoun\\Documents\\Documents\\Nuku Data\\ETL-real-estate-prices\\Data\"\n",
    "PATH_DATA_RAW = rf\"{PATH_DATA}\\Raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PATH_DATA):\n",
    "    print('Le dossier Data existe déja.')\n",
    "else: \n",
    "    os.mkdir(PATH_DATA)\n",
    "    print('Le dossier Data a été créé avec succès.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PATH_DATA_RAW):\n",
    "    print('Le dossier Data Raw existe déja.')\n",
    "else: \n",
    "    os.mkdir(PATH_DATA_RAW)\n",
    "    print('Le dossier Data Raw a été créé avec succès.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement données d'une page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.immoscout24.ch/en/house/buy/city-bern?pn=1&r=40\"\n",
    "# response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = bs(html, \"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descs = soup.find_all('div', {'class': \"Box-cYFBPY Flex-feqWzG MetaBody-iCkzuU JVKAR dCDRxm dUKbXG\"})\n",
    "\n",
    "# data = []\n",
    "    \n",
    "\n",
    "# for i,des in enumerate(descs):\n",
    "#     content = {'id': i,\n",
    "#                 'title': None,\n",
    "#                 'description': None,\n",
    "#                 'room': None,\n",
    "#                 'surface': None,\n",
    "#                 'price': None\n",
    "#                 }\n",
    "#     content['title'] = des.find('h2').get_text()\n",
    "    \n",
    "#     if des.find('p'):\n",
    "#         content['description'] = des.find('p').get_text()\n",
    "#     else:\n",
    "#         content['description'] = None\n",
    "\n",
    "\n",
    "#     list_reste = des.find('h3').get_text(strip=True).split('CHF')\n",
    "#     if len(list_reste) == 2:\n",
    "#         price = list_reste[1]\n",
    "#         price = price.replace('CHF ', '')\n",
    "#         price = price.replace('.—', '')\n",
    "#         price = price.replace(',', '').strip()\n",
    "#     else:\n",
    "#         price = None\n",
    "        \n",
    "\n",
    "#     number_room = list_reste[0].split(',')[0]\n",
    "#     number_room = number_room.replace('rooms', '')\n",
    "    \n",
    "#     surface = list_reste[0].split(',')[1]\n",
    "#     surface = surface.replace('m²', '')\n",
    "    \n",
    "    \n",
    "#     content['room'] = number_room.strip()\n",
    "#     content['surface'] = surface.strip()\n",
    "#     content['price'] = price\n",
    "#     data.append(content)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = 1\n",
    "# page_path = rf\"{PATH_DATA_RAW}\"    \n",
    "\n",
    "# nom_fichier = rf\"{page_path}/data_page_{page}.json\"\n",
    "# if os.path.exists(nom_fichier):\n",
    "#     print(f'Le fichier data_page_{page} existe déja.')\n",
    "# else: \n",
    "#     with open(nom_fichier, \"w\", encoding=\"utf-8\") as fichier:\n",
    "#         json.dump(data, fichier, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(nom_fichier)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement données de plusieurs pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page = 1\n",
    "# url = f\"https://www.immoscout24.ch/en/house/buy/city-bern?r=40\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "\n",
    "# while response.status_code == 200 :\n",
    "#     url = f\"https://www.immoscout24.ch/en/house/buy/city-bern?pn={page}&r=40\"\n",
    "#     response = requests.get(url)\n",
    "#     html = response.content\n",
    "#     soup = bs(html, \"html\")\n",
    "#     descs = soup.find_all('div', {'class': \"Box-cYFBPY Flex-feqWzG MetaBody-iCkzuU JVKAR dCDRxm dUKbXG\"})\n",
    "#     data = []\n",
    "    \n",
    "#     for i,des in enumerate(descs):\n",
    "#         content = {'id': i,\n",
    "#                     'title': None,\n",
    "#                     'description': None,\n",
    "#                     'room': None,\n",
    "#                     'surface': None,\n",
    "#                     'price': None\n",
    "#                     }\n",
    "#         content['title'] = des.find('h2').get_text()\n",
    "    \n",
    "#         if des.find('p'):\n",
    "#             content['description'] = des.find('p').get_text()\n",
    "#         else:\n",
    "#             content['description'] = None\n",
    "\n",
    "#         list_reste = des.find('h3').get_text(strip=True).split('CHF')\n",
    "#         if len(list_reste) == 2:\n",
    "#             price = list_reste[1]\n",
    "#             price = price.replace('CHF ', '')\n",
    "#             price = price.replace('.—', '')\n",
    "#             price = price.replace(',', '').strip()\n",
    "#         else:\n",
    "#             price = None\n",
    "            \n",
    "        \n",
    "#         list_rooms = list_reste[0].split('rooms')\n",
    "#         if len(list_rooms) == 2:\n",
    "#             liste_room = des.find('h3').get_text(strip=True).split('rooms')\n",
    "#             number_room = liste_room[0].replace('rooms','').strip()\n",
    "#             list_for_surface = list_rooms[1].split('m²')\n",
    "#             surface = list_for_surface[0].replace(',','').strip()\n",
    "#         else:\n",
    "#             if \"rooms\" in list_rooms:\n",
    "#                 number_room = list_rooms.replace('rooms','').strip()       \n",
    "        \n",
    "#         content['room'] = number_room.strip()\n",
    "#         content['surface'] = surface.strip()\n",
    "#         content['price'] = price\n",
    "#         data.append(content)\n",
    "        \n",
    "        \n",
    "\n",
    "#     page_path = rf\"{PATH_DATA_RAW}/\"\n",
    "\n",
    "#     nom_fichier = rf\"{page_path}/data_page_{page}.json\"\n",
    "#     if os.path.exists(nom_fichier):\n",
    "#         print(f'Le fichier data_page_{page} existe déja.\\n')\n",
    "#     else: \n",
    "#         with open(nom_fichier, \"w\", encoding=\"utf-8\") as fichier:  \n",
    "#             json.dump(data, fichier, ensure_ascii=False)\n",
    "#             fichier.close()\n",
    "            \n",
    "#     page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_page = rf'{PATH_DATA_RAW}\\data_page_2.json'\n",
    "# df = pd.read_json(path_page)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOUVEAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_citya = r\"https://www.citya.com/annonces/vente/appartement,maison?sort=b.dateMandat&direction=desc&page={page}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PATH_DATA_RAW + \"/Citya/json\"):\n",
    "    print('Le dossier Data Raw citya existe déja.')\n",
    "else: \n",
    "    os.mkdir(PATH_DATA_RAW+ \"/Citya/json\")\n",
    "    print('Le dossier Data Raw citya a été créé avec succès.')\n",
    "    \n",
    "if os.path.exists(PATH_DATA_RAW + \"/Citya/parquet\"):\n",
    "    print('Le dossier Data Raw citya existe déja.')\n",
    "else: \n",
    "    os.mkdir(PATH_DATA_RAW+ \"/Citya/parquet\")\n",
    "    print('Le dossier Data Raw citya a été créé avec succès.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CITYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "url = fr\"https://www.citya.com/annonces/vente/appartement,maison?sort=b.dateMandat&direction=desc&page={page}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "html = response.content\n",
    "soup = bs(html, \"html\")\n",
    "# print(\"Status code: \", response.status_code)\n",
    "descs = soup.find_all('div', {'class': \"infos\"})\n",
    "# print(\"DESCS: \", descs)\n",
    "\n",
    "data_citya = []\n",
    "    \n",
    "\n",
    "for i,des in enumerate(descs):\n",
    "    content = {'id': i,\n",
    "                'title': None,\n",
    "                'description': None,\n",
    "                'type': None,\n",
    "                'surface': None,\n",
    "                'price': None,\n",
    "                'city': None,\n",
    "                'postal_code': None,\n",
    "                'number_pieces': None,\n",
    "                }\n",
    "    \n",
    "    # print(\"DES: \", des)\n",
    "    content['title'] = des.find('h3').get_text().strip().replace('\\n','')\n",
    "    \n",
    "    \n",
    "    content['description'] = des.find('p', class_=\"description-start\").get_text() + \"\\n\" + \\\n",
    "                            des.find('span', class_=\"description-more\").get_text()\n",
    "    content['description'] = content['description'].replace('\\xa0','')\n",
    "    # print(\"DESCRIPTION: \", content['description'])\n",
    "    \n",
    "    \n",
    "    cities = des.find('p', class_=\"ville\").get_text().strip()\n",
    "    \n",
    "    content['city'] = \" \".join(re.findall('[a-zA-ZÀ-ȕ]+', cities))\n",
    "    # print(\"CITY: \", content['city'])\n",
    "    \n",
    "    content['postal_code'] = re.findall('[0-9]+', cities)[-1]\n",
    "    # print(\"POSTAL CODE: \", content['postal_code'])\n",
    "    \n",
    "    content['price'] = int(des.find('p', class_=\"prix\").find('strong').get_text().replace('\\u202f','').replace('\\xa0€','').split()[0])\n",
    "    # print(\"PRICE: \", content['price'])\n",
    "    \n",
    "    content['type'] = des.find('h3').get_text().split()[0]\n",
    "    # print(\"TYPE: \", content['type'])\n",
    "    \n",
    "    content['number_pieces'] = int(des.find('h3').find('strong').get_text().split()[0])\n",
    "    # print(\"NUMBER PIECES: \", content['number_pieces'])\n",
    "    \n",
    "    content['surface'] = des.find('h3').get_text().split()[-1]\n",
    "    # print(\"SURFACE: \", content['surface'])\n",
    "\n",
    "\n",
    "    data_citya.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_citya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "url = fr\"https://www.citya.com/annonces/vente/appartement,maison?sort=b.dateMandat&direction=desc&page={page}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "while response.status_code == 200 :\n",
    "    html = response.content\n",
    "    soup = bs(html, \"html\")\n",
    "    # print(\"Status code: \", response.status_code)\n",
    "    descs = soup.find_all('div', {'class': \"infos\"})\n",
    "    # print(\"DESCS: \", descs)\n",
    "\n",
    "    data_citya = []\n",
    "        \n",
    "\n",
    "    for i,des in enumerate(descs):\n",
    "        content = {'id': i,\n",
    "                    'title': None,\n",
    "                    'description': None,\n",
    "                    'type': None,\n",
    "                    'surface': None,\n",
    "                    'price': None,\n",
    "                    'city': None,\n",
    "                    'postal_code': None,\n",
    "                    'number_pieces': None,\n",
    "                    }\n",
    "        \n",
    "        # print(\"DES: \", des)\n",
    "        content['title'] = des.find('h3').get_text().strip().replace('\\n','')\n",
    "        \n",
    "        \n",
    "        content['description'] = des.find('p', class_=\"description-start\").get_text() + \"\\n\" + \\\n",
    "                                des.find('span', class_=\"description-more\").get_text()\n",
    "        content['description'] = content['description'].replace('\\xa0','')\n",
    "        # print(\"DESCRIPTION: \", content['description'])\n",
    "        \n",
    "        \n",
    "        cities = des.find('p', class_=\"ville\").get_text().strip()\n",
    "        \n",
    "        content['city'] = \" \".join(re.findall('[a-zA-ZÀ-ȕ]+', cities))\n",
    "        # print(\"CITY: \", content['city'])\n",
    "        \n",
    "        content['postal_code'] = re.findall('[0-9]+', cities)[-1]\n",
    "        # print(\"POSTAL CODE: \", content['postal_code'])\n",
    "        \n",
    "        content['price'] = int(des.find('p', class_=\"prix\").find('strong').get_text().replace('\\u202f','').replace('\\xa0€','').split()[0])\n",
    "        # print(\"PRICE: \", content['price'])\n",
    "        \n",
    "        content['type'] = des.find('h3').get_text().split()[0]\n",
    "        # print(\"TYPE: \", content['type'])\n",
    "        \n",
    "        content['number_pieces'] = int(des.find('h3').find('strong').get_text().split()[0])\n",
    "        # print(\"NUMBER PIECES: \", content['number_pieces'])\n",
    "        \n",
    "        content['surface'] = des.find('h3').get_text().split()[-1]\n",
    "        # print(\"SURFACE: \", content['surface'])\n",
    "\n",
    "\n",
    "        data_citya.append(content)\n",
    "        \n",
    "        \n",
    "        page_path = rf\"{PATH_DATA_RAW}/Citya/\"\n",
    "\n",
    "        nom_fichier = rf\"{page_path}/json/data_page_{page}.json\"\n",
    "        if os.path.exists(nom_fichier):\n",
    "            print(f'Le fichier data_page_{page} existe déja.\\n')\n",
    "        else: \n",
    "            with open(nom_fichier, \"w\", encoding=\"utf-8\") as fichier:  \n",
    "                json.dump(data_citya, fichier, ensure_ascii=False)\n",
    "                fichier.close()\n",
    "                \n",
    "        \n",
    "        parquet_path = rf\"{page_path}/parquet/data_page_{page}.parquet\"\n",
    "        if os.path.exists(parquet_path):\n",
    "            print(f'Le fichier data_page_{page}.parquet existe déjà.\\n')\n",
    "        else:\n",
    "            # Convertir la liste en un DataFrame pandas\n",
    "            df = pd.DataFrame(data_citya)\n",
    "\n",
    "            # Enregistrer le DataFrame au format Parquet\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            pq.write_table(table, parquet_path, compression='gzip')\n",
    "            print(f'Les données ont été enregistrées au format Parquet dans {parquet_path}.\\n')\n",
    "\n",
    "        \n",
    "        \n",
    "        page += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
